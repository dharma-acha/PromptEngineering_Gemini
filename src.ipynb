{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qegy3bZJuUFB"
      },
      "source": [
        "# Prompt Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hohC8v5uUFD"
      },
      "source": [
        "Prompt engineering is the art and science of crafting questions or instructions to guide artificial intelligence models, particularly in generating responses or content that meet specific criteria or intentions. It's a crucial skill for working with models like GPT (Generative Pre-trained Transformer), enabling users to fine-tune the AI's output without altering the underlying model. This practice is especially relevant as AI becomes more integrated into creative, analytical, and decision-making processes across various industries.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is a Prompt ?**\n",
        "\n",
        "A prompt in generative AI models is the textual input provided by the users to guide the model's output.\n",
        "\n",
        "This textual input range from simple questions to detailed descriptions or specific tasks.\n",
        "\n",
        "When we consider image generation models like DALLE-3, these prompts are generally descriptive, whereas in LLM's such as GPT-4 or Gemini, they vary from simple queries to complex problem statements"
      ],
      "metadata": {
        "id": "Fv5U7U5EyswG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO4IymmQuUFE"
      },
      "source": [
        "The popular LLM (Language Model) models include:\n",
        "\n",
        "**GPT-2 (Generative Pre-trained Transformer 2):**\n",
        "\n",
        "GPT-2 is the predecessor to GPT-3 and is also developed by OpenAI. It has 1.5 billion parameters and is known for its impressive text generation capabilities.\n",
        "\n",
        "**GPT-3 (Generative Pre-trained Transformer 3):**\n",
        "\n",
        "Developed by OpenAI, GPT-3 is one of the most advanced language models available. It has 175 billion parameters and can generate human-like text across a wide range of tasks.\n",
        "\n",
        "**BERT (Bidirectional Encoder Representations from Transformers):**\n",
        "\n",
        "BERT, developed by Google, is a transformer-based model that has achieved state-of-the-art performance on various natural language processing tasks. It is widely used for tasks like text classification, named entity recognition, and question answering.\n",
        "\n",
        "**RoBERTa (Robustly Optimized BERT Pretraining Approach):**\n",
        "\n",
        "RoBERTa is a variant of BERT that was developed by Facebook AI. It is trained using a larger corpus and longer training duration, resulting in improved performance on various language understanding tasks.\n",
        "\n",
        "**T5 (Text-to-Text Transfer Transformer):**\n",
        "\n",
        "T5, developed by Google, is a versatile language model that can be fine-tuned for a wide range of natural language processing tasks. It is known for its ability to perform tasks like text summarization, translation, and question answering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlJQ6oNHuUFE"
      },
      "source": [
        "The internal workings of prompt engineering, especially in the context of models like GPT (Generative Pre-trained Transformer) from OpenAI, involve a blend of natural language understanding, machine learning, and the strategic crafting of input to steer the AI's response in a desired direction. While the specifics of the AI's internal mechanisms are complex, we can demystify the process to an extent, focusing on the interaction between prompts and the AI's response generation.\n",
        "\n",
        "### Pre-trained Models and Tokenization\n",
        "\n",
        "At the core of GPT and similar models is a vast pre-trained neural network, developed by training on a massive corpus of text data. This training allows the model to understand and generate human-like text based on the patterns, relationships, and structures it has learned. When a prompt is given to the model, it's first tokenized—converted into a series of tokens (words or subwords) that the model can understand.\n",
        "\n",
        "### Understanding Context and Generating Responses\n",
        "\n",
        "The model uses the tokens from the prompt to understand the context and generate a response. Each token is processed in the context of the tokens that come before it, allowing the model to predict the most likely next token in the sequence. This process repeats for each new token generated, effectively \"rolling out\" a response until a stop condition is met (like reaching the maximum token limit or encountering a token that signifies the end of a text segment).\n",
        "\n",
        "### Adjusting Parameters\n",
        "\n",
        "In addition to crafting the content of the prompt itself, prompt engineering also involves adjusting various parameters that control the generation process, such as:\n",
        "\n",
        "- **Temperature:** Controls the randomness in the response generation. Higher temperatures lead to more varied and creative outputs, while lower temperatures produce more predictable and conservative text.\n",
        "- **Max Tokens:** Sets the length of the generated response, limiting how much the model can generate in one go.\n",
        "- **Top-p and Top-k Sampling:** These parameters control the diversity of the model's responses by limiting the pool of tokens the model considers at each step.\n",
        "\n",
        "### The Role of Prompt Engineering\n",
        "\n",
        "Prompt engineering comes into play by strategically crafting these input sequences (prompts) to guide the model towards generating a specific type of response. The effectiveness of prompt engineering relies on several factors:\n",
        "\n",
        "- **Clarity and Specificity:** A well-crafted prompt is clear and specific, guiding the model towards the desired output without ambiguity.\n",
        "- **Contextual Hints:** Including contextual information or specific instructions within the prompt can significantly influence the direction and quality of the generated content.\n",
        "- **Creative Constraints:** Sometimes, adding constraints or stylistic guidelines in the prompt can enhance creativity or relevance in the model's output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Prompts"
      ],
      "metadata": {
        "id": "3WQdwdOU4zEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Prompt*"
      ],
      "metadata": {
        "id": "a1iyMcYG44p5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sun is"
      ],
      "metadata": {
        "id": "Wh0fsLt44_R7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Output*"
      ],
      "metadata": {
        "id": "t9q-y6tU5ENV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sun is very bright today"
      ],
      "metadata": {
        "id": "r7ABsny45He8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating text with GPT-2"
      ],
      "metadata": {
        "id": "s0wjELDU1jFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install google-generativeai\n",
        "!pip install langchain\n",
        "!pip install python-dotenv\n",
        "!pip install autocorrect\n",
        "!pip install genai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hDfp3syOtbP",
        "outputId": "5760ed69-4f8f-414b-ba01-6b336cdf723d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.10)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.11.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai) (1.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->google-generativeai) (4.9)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.62.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.16)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.33)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.44)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.48)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: autocorrect in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: genai in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: ipython<9.0.0,>=8.10.0 in /usr/local/lib/python3.10/dist-packages (from genai) (8.23.0)\n",
            "Requirement already satisfied: openai<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from genai) (0.27.10)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from genai) (0.9.0)\n",
            "Requirement already satisfied: tiktoken<0.4.0,>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from genai) (0.3.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (0.19.1)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (0.1.6)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (3.0.43)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (2.16.1)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (0.6.3)\n",
            "Requirement already satisfied: traitlets>=5.13.0 in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (5.14.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (4.11.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<9.0.0,>=8.10.0->genai) (4.9.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai<0.28.0,>=0.27.0->genai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai<0.28.0,>=0.27.0->genai) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai<0.28.0,>=0.27.0->genai) (3.9.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.4.0,>=0.3.2->genai) (2023.12.25)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<9.0.0,>=8.10.0->genai) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<9.0.0,>=8.10.0->genai) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython<9.0.0,>=8.10.0->genai) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->genai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->genai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->genai) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (4.0.3)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython<9.0.0,>=8.10.0->genai) (2.0.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython<9.0.0,>=8.10.0->genai) (2.4.1)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython<9.0.0,>=8.10.0->genai) (0.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.1.0->stack-data->ipython<9.0.0,>=8.10.0->genai) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "KMoyk-9t1KSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from transformers import pipeline\n",
        "import openai\n",
        "import os\n",
        "import IPython\n",
        "from langchain.llms import OpenAI\n",
        "from dotenv import load_dotenv,find_dotenv\n",
        "import google.generativeai as genai\n",
        "from autocorrect import Speller"
      ],
      "metadata": {
        "id": "pvPuq83ABd2N"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading pre-trained GPT-2 model and tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Generating text based on a given prompt\n",
        "def generate_text(prompt, max_length=100, temperature=0.7):\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "    output = model.generate(input_ids, max_length=max_length, temperature=temperature, num_return_sequences=1)\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "# prompt\n",
        "prompt = \"Once upon a time,\"\n",
        "\n",
        "# Generate text with the given prompt\n",
        "generated_story = generate_text(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4H7Xjwx0I1E",
        "outputId": "cfd0725c-0b90-4f0c-ab1a-3e1b7e9bda52"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the generated story\n",
        "print(generated_story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw5VWUU819W_",
        "outputId": "4be52865-c6a6-480c-e6b5-a5b65b9d2af1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task"
      ],
      "metadata": {
        "id": "h0VoeoZ--pxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Pre-trained Model and Tokenizer**"
      ],
      "metadata": {
        "id": "ZWa7A6FBBOVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n"
      ],
      "metadata": {
        "id": "jerCQ1lEBVZA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt Customization**"
      ],
      "metadata": {
        "id": "2SvlcRYT-0O2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to customize prompt\n",
        "def customize_prompt():\n",
        "    prompt = input(\"Enter your prompt: \")\n",
        "    return prompt\n"
      ],
      "metadata": {
        "id": "g3KBLP4k2fCi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parameter Adjustment**"
      ],
      "metadata": {
        "id": "DQyJ7Ipi_CtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to adjust parameters\n",
        "def adjust_parameters():\n",
        "    max_length = int(input(\"Enter max length for generated text: \"))\n",
        "    temperature = float(input(\"Enter temperature for sampling (typically between 0.1 and 1): \"))\n",
        "    return max_length, temperature\n"
      ],
      "metadata": {
        "id": "k1k7v49q--Th"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Generation**"
      ],
      "metadata": {
        "id": "tafXcrJz_JnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate text based on a given prompt\n",
        "def generate_text(prompt, max_length=100, temperature=0.7):\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "    output = model.generate(input_ids, max_length=max_length, temperature=temperature, num_return_sequences=1)\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return generated_text\n"
      ],
      "metadata": {
        "id": "L6T6Hu7x_Hno"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interative Generation**"
      ],
      "metadata": {
        "id": "OuFuBVKt_UHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate text based on user input prompt and parameters\n",
        "def generate_text_interactively():\n",
        "    prompt = customize_prompt()\n",
        "    max_length, temperature = adjust_parameters()\n",
        "    generated_story = generate_text(prompt, max_length=max_length, temperature=temperature)\n",
        "    print(\"\\nGenerated Story:\")\n",
        "    print(generated_story)\n"
      ],
      "metadata": {
        "id": "fqV3VJ72_Qx7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function call**"
      ],
      "metadata": {
        "id": "3DeJGYal_dl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function\n",
        "def main():\n",
        "    generate_text_interactively()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoUYdvn0_agS",
        "outputId": "81334967-ff6c-4110-a4d3-366ad5f34de3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your prompt: An Apple\n",
            "Enter max length for generated text: 20\n",
            "Enter temperature for sampling (typically between 0.1 and 1): 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Story:\n",
            "An Apple Watch is a smartwatch that can be worn on your wrist. It's a smartwatch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch Generation"
      ],
      "metadata": {
        "id": "26oK1vlqXvrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})  # Add padding token\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Function to generate text based on a given prompt\n",
        "def generate_text(prompt, max_length=100, temperature=0.7):\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "    output = model.generate(input_ids, max_length=max_length, temperature=temperature, num_return_sequences=1)\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "# Function to adjust parameters\n",
        "def adjust_parameters():\n",
        "    max_length = int(input(\"Enter max length for generated text: \"))\n",
        "    temperature = float(input(\"Enter temperature for sampling (typically between 0.1 and 1): \"))\n",
        "    return max_length, temperature\n",
        "\n",
        "# Function for batch generation\n",
        "def batch_generate_text(prompts, max_length=100, temperature=0.7):\n",
        "    generated_texts = []\n",
        "    for prompt in prompts:\n",
        "        generated_text = generate_text(prompt, max_length=max_length, temperature=temperature)\n",
        "        generated_texts.append(generated_text)\n",
        "    return generated_texts\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Get prompts from the user\n",
        "    num_prompts = int(input(\"Enter the number of prompts: \"))\n",
        "    prompts = []\n",
        "    for i in range(num_prompts):\n",
        "        prompt = input(f\"Enter prompt {i + 1}: \")\n",
        "        prompts.append(prompt)\n",
        "\n",
        "    # Adjust parameters\n",
        "    max_length, temperature = adjust_parameters()\n",
        "\n",
        "    # Batch generation\n",
        "    generated_stories = batch_generate_text(prompts, max_length=max_length, temperature=temperature)\n",
        "\n",
        "    print(\"\\nGenerated Stories:\")\n",
        "    for i, story in enumerate(generated_stories, start=1):\n",
        "        print(f\"\\nStory {i}:\")\n",
        "        print(story)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNv0cM31_kMB",
        "outputId": "edee8277-701c-48d2-ff58-0237161fb5cc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the number of prompts: 3\n",
            "Enter prompt 1: The sun\n",
            "Enter prompt 2: The vehicle\n",
            "Enter prompt 3: The road\n",
            "Enter max length for generated text: 20\n",
            "Enter temperature for sampling (typically between 0.1 and 1): 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Stories:\n",
            "\n",
            "Story 1:\n",
            "The sun was shining brightly in the sky, and the moon was shining brightly in the sky.\n",
            "\n",
            "\n",
            "Story 2:\n",
            "The vehicle was found in the parking lot of a home in the 600 block of South Main Street.\n",
            "\n",
            "Story 3:\n",
            "The road to the top of the mountain is a long, winding, winding road. The road is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Classification"
      ],
      "metadata": {
        "id": "jpkIfEPIMOCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the text classification pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Prompt for text classification\n",
        "prompt = \"Classify the sentiment of the provided text into positive, negative, or neutral:\"\n",
        "example = \"Example: 'I think the food was okay.'\"\n",
        "prompt_with_example = f\"{prompt}\\n{example}\\nText:\"\n",
        "\n",
        "# Get input text from the user\n",
        "text = input(prompt_with_example)\n",
        "\n",
        "# Perform text classification\n",
        "result = classifier(text)\n",
        "\n",
        "# Extract sentiment label\n",
        "sentiment = result[0]['label']\n",
        "\n",
        "# Print the sentiment\n",
        "print(\"Sentiment:\")\n",
        "print(sentiment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286,
          "referenced_widgets": [
            "dfbafd80a8484986b4c8707d4604bf55",
            "019a10d592b648b0b7c23de54611be60",
            "6741f6892b18414f9171da4545fc8755",
            "21df5ed4037b473ab81e878ab0288055",
            "675ce256be1c45b1bc83ce710bac5ff0",
            "c93efe034e0b4059a46aae8acc444fa2",
            "f806abd1b79b4bc9b06ae0d80ca9ace3",
            "eb49ebbe613b4ef89f7d5f1496c66245",
            "ef2db54825a146f28c7ad3ccd509ef8c",
            "abca66a541da443f9ea2f5bb6f820109",
            "6ae09a84b8bd460a8a55eef945831d59",
            "1e952a06802a4f8b9180325c9751af89",
            "3f4bbdf0037d414aa469a24246d61479",
            "f73afdda37b14e23ad84eee774ef6cd7",
            "e27c302d5d6c41c4a59d4330618b1158",
            "e7204b57126a48eeaca604401a399098",
            "d241d09167244fadafa234ced6213815",
            "5f7f8f0ca99446bdac934fb1ae363090",
            "e31a04423ce046daa3c114ccc0e96da8",
            "348fb196d82e4db4af7f4013e9431506",
            "e726c026926a4885a665a5500ae1a238",
            "2649a94d4d8c4ac793dd6b2a98c1c870",
            "1c97f5391f104cd199072079555ee8f0",
            "ef93e2c727bb498f9f7c382ec2d00812",
            "f9a56ee50a124aa19328a8b871bc58b0",
            "f31b210393cc4716b89277a8648a902b",
            "10b0355a22304da1992208747ffb347e",
            "948faae7fac1407f974aa0865550158c",
            "00670e03d24642e8ba3cb70b5a51638e",
            "dcd1823225e245bca87f521c81e7c60f",
            "cbc63c1874b74a028f3d403fc8c7cea1",
            "1d53866ca7144013a10df3270bf8c621",
            "a314685609684eb3a97bf3804db3e891",
            "2c84722ba3d44b43abd0bc3571a0f790",
            "a31486e2455b4306b5dc679f055fd90f",
            "c14f57e333504108a549449051b32d45",
            "d1ef2ea315734f6bbf28543ab622643f",
            "16590c2699cb45488b4893805ddd7d09",
            "83c8790b266b4fc58883476f6764b6e4",
            "497d513f630346bb8f7da6c89171718d",
            "28e336454d3d412a96077e1073f8f0af",
            "a6169db2e33e4efca407eaf66433018f",
            "3d43ae3358b042b5af1bff6978e82335",
            "cc4856d7d2504adebbf16185286e0f7f"
          ]
        },
        "id": "TrL46yrsDowI",
        "outputId": "7c788d4c-3fd2-4000-d262-088f3595bd38"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfbafd80a8484986b4c8707d4604bf55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e952a06802a4f8b9180325c9751af89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c97f5391f104cd199072079555ee8f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c84722ba3d44b43abd0bc3571a0f790"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classify the sentiment of the provided text into positive, negative, or neutral:\n",
            "Example: 'I think the food was okay.'\n",
            "Text:The vacation was not good\n",
            "Sentiment:\n",
            "NEGATIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI"
      ],
      "metadata": {
        "id": "nJCZrYzaAjMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_=load_dotenv(find_dotenv())\n",
        "\n",
        "my_key=os.environ[\"my_key\"]"
      ],
      "metadata": {
        "id": "ZUBUlFGHHAaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "\n",
        "# API configuration\n",
        "openai.api_key = os.getenv(\"my_key\")\n",
        "\n",
        "# for LangChain\n",
        "os.environ[\"my_key\"] = os.getenv(\"my_key\")"
      ],
      "metadata": {
        "id": "MyRlqHbmHf9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_open_params(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=256,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "):\n",
        "    \"\"\" set openai parameters\"\"\"\n",
        "\n",
        "    openai_params = {}\n",
        "\n",
        "    openai_params['model'] = model\n",
        "    openai_params['temperature'] = temperature\n",
        "    openai_params['max_tokens'] = max_tokens\n",
        "    openai_params['top_p'] = top_p\n",
        "    openai_params['frequency_penalty'] = frequency_penalty\n",
        "    openai_params['presence_penalty'] = presence_penalty\n",
        "    return openai_params\n",
        "\n",
        "def get_completion(params, messages):\n",
        "    \"\"\" GET completion from openai api\"\"\"\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model = params['model'],\n",
        "        messages = messages,\n",
        "        temperature = params['temperature'],\n",
        "        max_tokens = params['max_tokens'],\n",
        "        top_p = params['top_p'],\n",
        "        frequency_penalty = params['frequency_penalty'],\n",
        "        presence_penalty = params['presence_penalty'],\n",
        "    )\n",
        "    return response"
      ],
      "metadata": {
        "id": "EhJ9tfELHgAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Started with Gemini"
      ],
      "metadata": {
        "id": "u_VahkTGANKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Load API key from environment variable\n",
        "api_key = os.getenv(\"my_key\")\n",
        "\n",
        "# Check if API key is available\n",
        "if api_key is None:\n",
        "    print(\"Please set the GENAI_API_KEY environment variable in the .env file.\")\n",
        "    exit()\n",
        "\n",
        "# Configure with the loaded API key\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "OE05XX7k5oPG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Correction"
      ],
      "metadata": {
        "id": "SUrMFKIH2R2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the model\n",
        "generation_config = {\n",
        "    \"temperature\": 0,\n",
        "    \"top_p\": 1,\n",
        "    \"top_k\": 1,\n",
        "    \"max_output_tokens\": 2048,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    }\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-pro\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)\n",
        "\n",
        "# Initialize spell checker\n",
        "spell = Speller(lang='en')\n",
        "\n",
        "# Function to correct text\n",
        "def correct_text(text):\n",
        "    return spell(text)\n",
        "\n",
        "# Take input from the user\n",
        "input_text = input(\"Enter the text you want to correct: \")\n",
        "\n",
        "# Correct the input text\n",
        "corrected_text = correct_text(input_text)\n",
        "\n",
        "# Generate the corrected content\n",
        "corrected_response = model.generate_content([corrected_text])\n",
        "\n",
        "# Print the corrected text\n",
        "print(\"Corrected text:\")\n",
        "print(corrected_response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "BSRtxI7W2NlD",
        "outputId": "e9b9063a-75fb-4236-b1cd-765e0ffe4a0b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text you want to correct: Thes is an exaple of incoreect texxt.\n",
            "Corrected text:\n",
            "This is an example of correct text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question Answering"
      ],
      "metadata": {
        "id": "_BBqHiFR2Zj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the model\n",
        "generation_config = {\n",
        "    \"temperature\": 0,\n",
        "    \"top_p\": 1,\n",
        "    \"top_k\": 1,\n",
        "    \"max_output_tokens\": 2048,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    }\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-pro\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)\n",
        "\n",
        "# Function to perform question answering\n",
        "def perform_question_answering(context, question):\n",
        "    # Generate answer using gemini model\n",
        "    response = model.generate_content([context, question])\n",
        "    if response.candidates and response.candidates[0].content.parts:\n",
        "        answer = response.candidates[0].content.parts[0].text\n",
        "        return answer\n",
        "    else:\n",
        "        return \"Sorry, I couldn't find an answer.\"\n",
        "\n",
        "# Take input from the user\n",
        "context = input(\"Enter the context or passage: \")\n",
        "question = input(\"Enter the question: \")\n",
        "\n",
        "# Perform question answering\n",
        "answer = perform_question_answering(context, question)\n",
        "\n",
        "# Print the answer\n",
        "print(\"Answer:\")\n",
        "print(answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "UwPGvrey2iIg",
        "outputId": "ff6389be-58df-4b67-d150-5255e448078e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the context or passage: The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower.\n",
            "Enter the question: Who designed the Eiffel Tower?\n",
            "Answer:\n",
            "Gustave Eiffel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Annotation"
      ],
      "metadata": {
        "id": "IiakAZHg2nop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Load SpaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Set up the model\n",
        "generation_config = {\n",
        "    \"temperature\": 0,\n",
        "    \"top_p\": 1,\n",
        "    \"top_k\": 1,\n",
        "    \"max_output_tokens\": 2048,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    }\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-pro\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)\n",
        "\n",
        "# Function for text annotation\n",
        "def annotate_text(input_text):\n",
        "    doc = nlp(input_text)\n",
        "    annotations = {\n",
        "        \"text\": input_text,\n",
        "        \"tokens\": [{\"text\": token.text, \"pos\": token.pos_, \"dep\": token.dep_} for token in doc],\n",
        "        \"entities\": [{\"text\": ent.text, \"label\": ent.label_} for ent in doc.ents]\n",
        "    }\n",
        "    return annotations\n",
        "\n",
        "# Take input from the user\n",
        "input_text = input(\"Enter the text you want to Annotate: \")\n",
        "\n",
        "# Generate the summarized content\n",
        "summarized_response = model.generate_content([input_text])\n",
        "\n",
        "\n",
        "# Annotate the input text\n",
        "annotations = annotate_text(input_text)\n",
        "print(\"\\nText Annotations:\")\n",
        "print(annotations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "_uohBDL92sUY",
        "outputId": "482dbe27-3043-4491-a4d0-58975e4ee195"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text you want to Annotate: Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. These processes include learning (the acquisition of information and rules for using the information), reasoning (using rules to reach approximate or definite conclusions), and self-correction. Particular applications of AI include expert systems, speech recognition, and machine vision.\n",
            "\n",
            "Text Annotations:\n",
            "{'text': 'Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. These processes include learning (the acquisition of information and rules for using the information), reasoning (using rules to reach approximate or definite conclusions), and self-correction. Particular applications of AI include expert systems, speech recognition, and machine vision.', 'tokens': [{'text': 'Artificial', 'pos': 'ADJ', 'dep': 'amod'}, {'text': 'intelligence', 'pos': 'NOUN', 'dep': 'nsubj'}, {'text': '(', 'pos': 'PUNCT', 'dep': 'punct'}, {'text': 'AI', 'pos': 'PROPN', 'dep': 'appos'}, {'text': ')', 'pos': 'PUNCT', 'dep': 'punct'}, {'text': 'is', 'pos': 'AUX', 'dep': 'ROOT'}, {'text': 'the', 'pos': 'DET', 'dep': 'det'}, {'text': 'simulation', 'pos': 'NOUN', 'dep': 'attr'}, {'text': 'of', 'pos': 'ADP', 'dep': 'prep'}, {'text': 'human', 'pos': 'ADJ', 'dep': 'amod'}, {'text': 'intelligence', 'pos': 'NOUN', 'dep': 'compound'}, {'text': 'processes', 'pos': 'NOUN', 'dep': 'pobj'}, {'text': 'by', 'pos': 'ADP', 'dep': 'prep'}, {'text': 'machines', 'pos': 'NOUN', 'dep': 'pobj'}, {'text': ',', 'pos': 'PUNCT', 'dep': 'punct'}, {'text': 'especially', 'pos': 'ADV', 'dep': 'advmod'}, {'text': 'computer', 'pos': 'NOUN', 'dep': 'compound'}, {'text': 'systems', 'pos': 'NOUN', 'dep': 'appos'}, {'text': '.', 'pos': 'PUNCT', 'dep': 'punct'}, {'text': 'These', 'pos': 'DET', 'dep': 'det'}, {'text': 'processes', 'pos': 'NOUN', 'dep': 'nsubj'}, {'text': 'include', 'pos': 'VERB', 'dep': 'ROOT'}, {'text': 'learning', 'pos': 'VERB', 'dep': 'xcomp'}, {'text': '(', 'pos': 'PUNCT', 'dep': 'punct'}, {'text': 'the', 'pos': 'DET', 'dep': 'det'}, {'text': 'acquisition', 'pos': 'NOUN', 'dep': 'dobj'}, {'text': 'of', 'pos': 'ADP', 'dep': 'prep'}, {'text': 'information', 'pos': 'NOUN', 'dep': 'pobj'}, {'text': 'and', 'pos': 'CCONJ', 'dep': 'cc'}, {'text': 'rules', 'pos': 'NOUN', 'dep': 'conj'}, {'text': 'for', 'pos': 'ADP', 'dep': 'prep'}, {'text': 'using', 'pos': 'VERB', 'dep': 'pcomp'}, {'text': 'the', 'pos': 'DET', 'dep': 'det'}, {'text': 'information', 'pos': 'NOUN', 'dep': 'dobj'}, {'text': ')', 'pos': 'PUNCT', 'dep': 'punct'}, {'text': ',', 'pos': 'PUNCT', 'dep': 'punct'}, {'text': 'reasoning', 'pos': 'VERB', 'dep': 'conj'}, {'text': '(', 'pos': 'PUNCT', 'dep': 'punct'}, {'text': 'using', 'pos': 'VERB', 'dep': 'advcl'}, {'text': 'rules', 'pos': 'NOUN', 'dep': 'dobj'}, {'text': 'to', 'pos': 'PART', 'dep': 'aux'}, {'text': 'reach', 'pos': 'VERB', 'dep': 'xcomp'}, {'text': 'approximate', 'pos': 'ADJ', 'dep': 'amod'}, {'text': 'or', 'pos': 'CCONJ', 'dep': 'cc'}, {'text': 'definite', 'pos': 'ADJ', 'dep': 'conj'}, {'text': 'conclusions', 'pos': 'NOUN', 'dep': 'dobj'}, {'text': ')', 'pos': 'PUNCT', 'dep': 'punct'}, {'text': ',', 'pos': 'PUNCT', 'dep': 'punct'}, {'text': 'and', 'pos': 'CCONJ', 'dep': 'cc'}, {'text': 'self', 'pos': 'NOUN', 'dep': 'compound'}, {'text': '-', 'pos': 'PUNCT', 'dep': 'punct'}, {'text': 'correction', 'pos': 'NOUN', 'dep': 'conj'}, {'text': '.', 'pos': 'PUNCT', 'dep': 'punct'}, {'text': 'Particular', 'pos': 'ADJ', 'dep': 'amod'}, {'text': 'applications', 'pos': 'NOUN', 'dep': 'nsubj'}, {'text': 'of', 'pos': 'ADP', 'dep': 'prep'}, {'text': 'AI', 'pos': 'PROPN', 'dep': 'pobj'}, {'text': 'include', 'pos': 'VERB', 'dep': 'ROOT'}, {'text': 'expert', 'pos': 'NOUN', 'dep': 'compound'}, {'text': 'systems', 'pos': 'NOUN', 'dep': 'dobj'}, {'text': ',', 'pos': 'PUNCT', 'dep': 'punct'}, {'text': 'speech', 'pos': 'NOUN', 'dep': 'compound'}, {'text': 'recognition', 'pos': 'NOUN', 'dep': 'conj'}, {'text': ',', 'pos': 'PUNCT', 'dep': 'punct'}, {'text': 'and', 'pos': 'CCONJ', 'dep': 'cc'}, {'text': 'machine', 'pos': 'NOUN', 'dep': 'compound'}, {'text': 'vision', 'pos': 'NOUN', 'dep': 'conj'}, {'text': '.', 'pos': 'PUNCT', 'dep': 'punct'}], 'entities': [{'text': 'AI', 'label': 'ORG'}, {'text': 'AI', 'label': 'ORG'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Summarization"
      ],
      "metadata": {
        "id": "pVFZde74J52T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the model\n",
        "generation_config = {\n",
        "    \"temperature\": 0,\n",
        "    \"top_p\": 1,\n",
        "    \"top_k\": 1,\n",
        "    \"max_output_tokens\": 2048,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    }\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-pro\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)\n",
        "\n",
        "# Take input from the user\n",
        "input_text = input(\"Enter the text you want to summarize: \")\n",
        "\n",
        "# Generate the summarized content\n",
        "summarized_response = model.generate_content([input_text])\n",
        "\n",
        "# Print the summarized text\n",
        "print(\"Summary:\")\n",
        "print(summarized_response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "8xG5XXSrJ8vP",
        "outputId": "90141309-2c55-4cea-e18f-cfc8b3f58825"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text you want to summarize: The Great Barrier Reef is the world's largest coral reef system composed of over 2,900 individual reefs and 900 islands stretching for over 2,300 kilometers (1,400 miles) over an area of approximately 344,400 square kilometers (133,000 square miles). It is located in the Coral Sea, off the coast of Queensland, Australia. The reef is home to a diverse range of marine life and is a popular destination for tourists and divers from around the world.\n",
            "Summary:\n",
            "**The Great Barrier Reef**\n",
            "\n",
            "**Size and Location:**\n",
            "\n",
            "* World's largest coral reef system\n",
            "* Over 2,900 individual reefs and 900 islands\n",
            "* Stretches for over 2,300 kilometers (1,400 miles)\n",
            "* Area of approximately 344,400 square kilometers (133,000 square miles)\n",
            "* Located in the Coral Sea, off the coast of Queensland, Australia\n",
            "\n",
            "**Significance:**\n",
            "\n",
            "* Home to a diverse range of marine life, including over 1,500 species of fish, 400 species of coral, and 4,000 species of mollusks\n",
            "* Provides food, shelter, and breeding grounds for many marine species\n",
            "* Supports a significant tourism industry, attracting divers and tourists from around the world\n",
            "\n",
            "**Threats:**\n",
            "\n",
            "* Climate change (rising sea temperatures and ocean acidification)\n",
            "* Pollution (runoff from agriculture and coastal development)\n",
            "* Overfishing\n",
            "* Coral bleaching (caused by stress from environmental factors)\n",
            "\n",
            "**Conservation Efforts:**\n",
            "\n",
            "* The Great Barrier Reef Marine Park was established in 1975 to protect the reef\n",
            "* Various management plans and regulations are in place to reduce threats and promote conservation\n",
            "* Research and monitoring programs are ongoing to track the health of the reef and inform conservation efforts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error Handling"
      ],
      "metadata": {
        "id": "aMBgCWkL4mvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the model\n",
        "generation_config = {\n",
        "    \"temperature\": 0,\n",
        "    \"top_p\": 1,\n",
        "    \"top_k\": 1,\n",
        "    \"max_output_tokens\": 2048,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    }\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-pro\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)\n",
        "\n",
        "# Function to generate content and raise an error\n",
        "def generate_content_with_error():\n",
        "    raise ValueError(\"An error occured, try again!!.\")\n",
        "\n",
        "# Example usage\n",
        "try:\n",
        "    generate_content_with_error()\n",
        "except ValueError as e:\n",
        "    print(\"Error:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MKJVIo17kXB",
        "outputId": "813db086-9b6c-4dd6-b707-7b92bc266d86"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: An error occured, try again!!.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Set up the model\n",
        "generation_config = {\n",
        "    \"temperature\": 0,\n",
        "    \"top_p\": 1,\n",
        "    \"top_k\": 1,\n",
        "    \"max_output_tokens\": 2048,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    }\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-pro\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)\n",
        "\n",
        "# Function to generate content and handle errors\n",
        "def generate_content_with_error_handling(prompt_parts):\n",
        "    try:\n",
        "        response = model.generate_content(prompt_parts)\n",
        "        if response.candidates:\n",
        "            return response.candidates[0].content.parts[0].text\n",
        "        else:\n",
        "            return \"No response generated.\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "# Example usage\n",
        "prompt_parts = [\"Your task is to extract model names from machine learning paper abstracts. Your response is an array of the model names in the format [\\\"model_name\\\"]. If you don't find model names in the abstract or you are not sure, return [\\\"NA\\\"]\\n\\nAbstract: Large Language Models (LLMs), such as ChatGPT and GPT-4, have revolutionized natural language processing research and demonstrated potential in Artificial General Intelligence (AGI). However, the expensive training and deployment of LLMs present challenges to transparent and open academic research. To address these issues, this project open-sources the Chinese LLaMA and Alpaca…\"]\n",
        "output = generate_content_with_error_handling(prompt_parts)\n",
        "if output.startswith(\"An error occurred\"):\n",
        "    print(\"Error:\", output)\n",
        "else:\n",
        "    print(output)\n"
      ],
      "metadata": {
        "id": "ouPk1QzN7v3E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1d65eec-03e2-4b8b-8404-9416af3b8586"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"LLMs\", \"ChatGPT\", \"GPT-4\", \"LLaMA\", \"Alpaca\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best Practices"
      ],
      "metadata": {
        "id": "-4P94or0Hgl5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rules of Thumb and Examples"
      ],
      "metadata": {
        "id": "VHAwrWEDICYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Put instructions at the beginning of the prompt and use ### or \"\"\" to separate the instruction and context**"
      ],
      "metadata": {
        "id": "SCBVe1mHI7AT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bad Prompt ❌**\n",
        "\n",
        "Summarize the text below as a bullet point list of the most important points.\n",
        "\n",
        "{text input here}"
      ],
      "metadata": {
        "id": "qVIjKOKLIwKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Better ✅:**\n",
        "\n",
        "Summarize the text below as a bullet point list of the most important points.\n",
        "\n",
        "Text: \"\"\"\n",
        "{text input here}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GqrAlG4bI40d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Be specific, descriptive and as detailed as possible about the desired context, outcome, length, format, style, etc**"
      ],
      "metadata": {
        "id": "HYEFt7KqJdiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bad Prompt ❌**\n",
        "\n",
        "Write a poem about OpenAI."
      ],
      "metadata": {
        "id": "YtFcB1NtJdoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Better ✅:**\n",
        "\n",
        "Write a short inspiring poem about OpenAI, focusing on the recent DALL-E product launch (DALL-E is a text to image ML model) in the style of a {famous poet}"
      ],
      "metadata": {
        "id": "5cop-8HqJdpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Articulate the desired output format through examples**"
      ],
      "metadata": {
        "id": "SHXQ0QErJdsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bad Prompt ❌:**\n",
        "\n",
        "Extract the entities mentioned in the text below. Extract the following 4 entity types: company names, people names, specific topics and themes.\n",
        "\n",
        "Text: {text}"
      ],
      "metadata": {
        "id": "K0xmEpP9JdtL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Better ✅:**\n",
        "\n",
        "Extract the important entities mentioned in the text below. First extract all company names, then extract all people names, then extract specific topics which fit the content and finally extract general overarching themes\n",
        "\n",
        "Desired format:\n",
        "Company names: <comma_separated_list_of_company_names>\n",
        "People names: -||-\n",
        "Specific topics: -||-\n",
        "General themes: -||-\n",
        "\n",
        "Text: {text}"
      ],
      "metadata": {
        "id": "zkoRsYL3JdxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.Start with zero-shot, then few-shot, neither of them worked, then fine-tune**"
      ],
      "metadata": {
        "id": "HiCJQ9rIKa4X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**✅ Zero-shot**\n",
        "\n",
        "Extract keywords from the below text.\n",
        "\n",
        "Text: {text}\n",
        "\n",
        "Keywords:"
      ],
      "metadata": {
        "id": "5wGU_pClKghy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**✅ Few-shot - provide a couple of examples**\n",
        "\n",
        "Extract keywords from the corresponding texts below.\n",
        "\n",
        "Text 1: Stripe provides APIs that web developers can use to integrate payment processing into their websites and mobile applications.\n",
        "Keywords 1: Stripe, payment processing, APIs, web developers, websites, mobile applications\n",
        "\n",
        "Text 2: OpenAI has trained cutting-edge language models that are very good at understanding and generating text. Our API provides access to these models and can be used to solve virtually any task that involves processing language.\n",
        "Keywords 2: OpenAI, language models, text processing, API.\n",
        "\n",
        "Text 3: {text}\n",
        "Keywords 3:"
      ],
      "metadata": {
        "id": "7e8zAcIpKgs_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.Reduce “fluffy” and imprecise descriptions**"
      ],
      "metadata": {
        "id": "IAhMXtENKguG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bad Prompt ❌:**\n",
        "\n",
        "The description for this product should be fairly short, a few sentences only, and not too much more."
      ],
      "metadata": {
        "id": "CwaRukV8LIEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Better ✅:**\n",
        "\n",
        "Use a 3 to 5 sentence paragraph to describe this product."
      ],
      "metadata": {
        "id": "0odVDXJwLIF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.Instead of just saying what not to do, say what to do instead**"
      ],
      "metadata": {
        "id": "K_j2cGLhLIIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bad Prompt ❌:**\n",
        "\n",
        "The following is a conversation between an Agent and a Customer. DO NOT ASK USERNAME OR PASSWORD. DO NOT REPEAT.\n",
        "\n",
        "Customer: I can’t log in to my account.\n",
        "Agent:"
      ],
      "metadata": {
        "id": "DmJkN3jLLIKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Better ✅:**\n",
        "\n",
        "The following is a conversation between an Agent and a Customer. The agent will attempt to diagnose the problem and suggest a solution, whilst refraining from asking any questions related to PII. Instead of asking for PII, such as username or password, refer the user to the help article www.samplewebsite.com/help/faq\n",
        "\n",
        "Customer: I can’t log in to my account.\n",
        "Agent:\n",
        "\n"
      ],
      "metadata": {
        "id": "FEDgndn1LIPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.Code Generation Specific - Use “leading words” to nudge the model toward a particular pattern**"
      ],
      "metadata": {
        "id": "Liva9XLbMOJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bad Prompt ❌:**\n",
        "\n",
        "Write a simple python function that\n",
        "\n",
        "1.Ask me for a number in mile\n",
        "\n",
        "2.It converts miles to kilometers"
      ],
      "metadata": {
        "id": "JkA3Dy_sMOXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding “import” makes the model that it should start writing in Python. (Likewise “SELECT” is a good hint for the start of a SQL statement.)"
      ],
      "metadata": {
        "id": "X4FD70R3MOYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Better ✅:**\n",
        "\n",
        "Write a simple python function that\n",
        "\n",
        "1.Ask me for a number in mile\n",
        "\n",
        "2.It converts miles to kilometers\n",
        "\n",
        "import"
      ],
      "metadata": {
        "id": "-jPS8BDeMOc8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rnqeeshwHjOz"
      },
      "execution_count": 36,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dfbafd80a8484986b4c8707d4604bf55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_019a10d592b648b0b7c23de54611be60",
              "IPY_MODEL_6741f6892b18414f9171da4545fc8755",
              "IPY_MODEL_21df5ed4037b473ab81e878ab0288055"
            ],
            "layout": "IPY_MODEL_675ce256be1c45b1bc83ce710bac5ff0"
          }
        },
        "019a10d592b648b0b7c23de54611be60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c93efe034e0b4059a46aae8acc444fa2",
            "placeholder": "​",
            "style": "IPY_MODEL_f806abd1b79b4bc9b06ae0d80ca9ace3",
            "value": "config.json: 100%"
          }
        },
        "6741f6892b18414f9171da4545fc8755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb49ebbe613b4ef89f7d5f1496c66245",
            "max": 629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef2db54825a146f28c7ad3ccd509ef8c",
            "value": 629
          }
        },
        "21df5ed4037b473ab81e878ab0288055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abca66a541da443f9ea2f5bb6f820109",
            "placeholder": "​",
            "style": "IPY_MODEL_6ae09a84b8bd460a8a55eef945831d59",
            "value": " 629/629 [00:00&lt;00:00, 17.4kB/s]"
          }
        },
        "675ce256be1c45b1bc83ce710bac5ff0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c93efe034e0b4059a46aae8acc444fa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f806abd1b79b4bc9b06ae0d80ca9ace3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb49ebbe613b4ef89f7d5f1496c66245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef2db54825a146f28c7ad3ccd509ef8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abca66a541da443f9ea2f5bb6f820109": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ae09a84b8bd460a8a55eef945831d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e952a06802a4f8b9180325c9751af89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f4bbdf0037d414aa469a24246d61479",
              "IPY_MODEL_f73afdda37b14e23ad84eee774ef6cd7",
              "IPY_MODEL_e27c302d5d6c41c4a59d4330618b1158"
            ],
            "layout": "IPY_MODEL_e7204b57126a48eeaca604401a399098"
          }
        },
        "3f4bbdf0037d414aa469a24246d61479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d241d09167244fadafa234ced6213815",
            "placeholder": "​",
            "style": "IPY_MODEL_5f7f8f0ca99446bdac934fb1ae363090",
            "value": "model.safetensors: 100%"
          }
        },
        "f73afdda37b14e23ad84eee774ef6cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e31a04423ce046daa3c114ccc0e96da8",
            "max": 267832558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_348fb196d82e4db4af7f4013e9431506",
            "value": 267832558
          }
        },
        "e27c302d5d6c41c4a59d4330618b1158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e726c026926a4885a665a5500ae1a238",
            "placeholder": "​",
            "style": "IPY_MODEL_2649a94d4d8c4ac793dd6b2a98c1c870",
            "value": " 268M/268M [00:03&lt;00:00, 31.8MB/s]"
          }
        },
        "e7204b57126a48eeaca604401a399098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d241d09167244fadafa234ced6213815": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f7f8f0ca99446bdac934fb1ae363090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e31a04423ce046daa3c114ccc0e96da8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "348fb196d82e4db4af7f4013e9431506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e726c026926a4885a665a5500ae1a238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2649a94d4d8c4ac793dd6b2a98c1c870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c97f5391f104cd199072079555ee8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef93e2c727bb498f9f7c382ec2d00812",
              "IPY_MODEL_f9a56ee50a124aa19328a8b871bc58b0",
              "IPY_MODEL_f31b210393cc4716b89277a8648a902b"
            ],
            "layout": "IPY_MODEL_10b0355a22304da1992208747ffb347e"
          }
        },
        "ef93e2c727bb498f9f7c382ec2d00812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_948faae7fac1407f974aa0865550158c",
            "placeholder": "​",
            "style": "IPY_MODEL_00670e03d24642e8ba3cb70b5a51638e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f9a56ee50a124aa19328a8b871bc58b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcd1823225e245bca87f521c81e7c60f",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbc63c1874b74a028f3d403fc8c7cea1",
            "value": 48
          }
        },
        "f31b210393cc4716b89277a8648a902b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d53866ca7144013a10df3270bf8c621",
            "placeholder": "​",
            "style": "IPY_MODEL_a314685609684eb3a97bf3804db3e891",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.67kB/s]"
          }
        },
        "10b0355a22304da1992208747ffb347e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "948faae7fac1407f974aa0865550158c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00670e03d24642e8ba3cb70b5a51638e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcd1823225e245bca87f521c81e7c60f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbc63c1874b74a028f3d403fc8c7cea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d53866ca7144013a10df3270bf8c621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a314685609684eb3a97bf3804db3e891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c84722ba3d44b43abd0bc3571a0f790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a31486e2455b4306b5dc679f055fd90f",
              "IPY_MODEL_c14f57e333504108a549449051b32d45",
              "IPY_MODEL_d1ef2ea315734f6bbf28543ab622643f"
            ],
            "layout": "IPY_MODEL_16590c2699cb45488b4893805ddd7d09"
          }
        },
        "a31486e2455b4306b5dc679f055fd90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83c8790b266b4fc58883476f6764b6e4",
            "placeholder": "​",
            "style": "IPY_MODEL_497d513f630346bb8f7da6c89171718d",
            "value": "vocab.txt: 100%"
          }
        },
        "c14f57e333504108a549449051b32d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28e336454d3d412a96077e1073f8f0af",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6169db2e33e4efca407eaf66433018f",
            "value": 231508
          }
        },
        "d1ef2ea315734f6bbf28543ab622643f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d43ae3358b042b5af1bff6978e82335",
            "placeholder": "​",
            "style": "IPY_MODEL_cc4856d7d2504adebbf16185286e0f7f",
            "value": " 232k/232k [00:00&lt;00:00, 4.31MB/s]"
          }
        },
        "16590c2699cb45488b4893805ddd7d09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83c8790b266b4fc58883476f6764b6e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "497d513f630346bb8f7da6c89171718d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28e336454d3d412a96077e1073f8f0af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6169db2e33e4efca407eaf66433018f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d43ae3358b042b5af1bff6978e82335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc4856d7d2504adebbf16185286e0f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}